{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8c8fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import seaborn as sb\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import sklearn.preprocessing as pre\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.utils import resample\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da1e1bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words={'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn','1','2','3','4','5','6','7','8','9','0','vs','le','la','de','none'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f999822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceNullByOne(columns):          #Replaces the Null Values by one\n",
    "    columnValue=columns[0]\n",
    "    if pd.isnull(columnValue):\n",
    "        return 1\n",
    "    else:\n",
    "        return columnValue\n",
    "    \n",
    "\n",
    "def replaceNullByZero(columns):         #Replaces the Null Values by zero\n",
    "    columnValue=columns[0]\n",
    "    if pd.isnull(columnValue):\n",
    "        return 0\n",
    "    else:\n",
    "        return columnValue\n",
    "\n",
    "\n",
    "def removeTime(columns):                #Removes the time from date object and just return Date\n",
    "    date=columns[0]\n",
    "    dateAndTime=date.split('T')\n",
    "    return dateAndTime[0]\n",
    "\n",
    "\n",
    "def calculateRate(columns):             #Calculates the rate of the numerator vs denominator\n",
    "    numerator=columns[0]\n",
    "    denominator=columns[1]\n",
    "    if(denominator>0):\n",
    "        return numerator/denominator\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "def categoryIdToCategory():              # creates a dictionary that maps category_id to category name\n",
    "   \n",
    "    categoryIdTocategory = {}\n",
    "    with open('category_id.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "        for category in data['items']:\n",
    "            categoryIdTocategory[category['id']] = category['snippet']['title']\n",
    "    return categoryIdTocategory\n",
    "    \n",
    "\n",
    "def convertCategoryIdToCategory(columns,categoryIdToCategory):      #Using the category to category Id dictionary returns the category name for the given category ID\n",
    "    categoryId=str(columns[0])\n",
    "    try:\n",
    "        category=categoryIdToCategory[categoryId]\n",
    "    except Exception as e:\n",
    "        category=0\n",
    "    return category\n",
    "\n",
    "\n",
    "def convertChannelIdToChannelTitle(columns,channelDictionary):      #Using the channel Dictionary converts the given channel ID to its Channel Name\n",
    "    channelId=columns[0]\n",
    "    try:\n",
    "        temp=channelDictionary[channelId]\n",
    "        channelName=temp['channelTitle']\n",
    "    except Exception as e:\n",
    "        channelName=1\n",
    "    return channelName\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80644e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessTheData(youTubeTrendingData,youTubeNonTrendingData):      #Preprocesses the Data to create one Dataframe containing both Trending and Non trending videos\n",
    "    #Preprocessing Trending Data\n",
    "    #Formatting the Date\n",
    "    youTubeTrendingData['trending_date'] = pd.to_datetime(youTubeTrendingData['trending_date'], format=\"%y.%d.%m\")\n",
    "    youTubeTrendingData['publish_time']=youTubeTrendingData[['publish_time']].apply(removeTime, axis=1)\n",
    "    youTubeTrendingData['publish_time'] = pd.to_datetime(youTubeTrendingData['publish_time'],format=(\"%Y-%m-%d\"))\n",
    "    #Calculating the age of the video\n",
    "    youTubeTrendingData['age']=(((youTubeTrendingData['trending_date']-youTubeTrendingData['publish_time']).dt.days)+1)\n",
    "    #Replace Null Values in Description by One\n",
    "    youTubeTrendingData['description']=youTubeTrendingData[['description']].apply(replaceNullByOne,axis=1)\n",
    "    \n",
    "    \n",
    "    #Preprocessing Non Trending data\n",
    "    #Adding the Data Retreived Date Column\n",
    "    youTubeNonTrendingData['obtained_date']=pd.to_datetime('2017-12-02',format=('%Y-%m-%d'))\n",
    "    #Fomatting the Date\n",
    "    youTubeNonTrendingData['publishedAt']=youTubeNonTrendingData[['publishedAt']].apply(removeTime, axis=1)\n",
    "    youTubeNonTrendingData['publishedAt']=pd.to_datetime(youTubeNonTrendingData['publishedAt'],format=(\"%Y-%m-%d\"))\n",
    "    #Calculate the age of the video\n",
    "    youTubeNonTrendingData['age']=((((pd.to_datetime('2017-12-02',format=(\"%Y-%m-%d\")))-youTubeNonTrendingData['publishedAt']).dt.days)+1)\n",
    "    #Remove the Null Values in the Data\n",
    "    youTubeNonTrendingData['tags']=youTubeNonTrendingData[['tags']].apply(replaceNullByOne,axis=1)\n",
    "    youTubeNonTrendingData['description']=youTubeNonTrendingData[['description']].apply(replaceNullByOne,axis=1)\n",
    "    youTubeNonTrendingData['commentCount']=youTubeNonTrendingData[['commentCount']].apply(replaceNullByZero,axis=1)\n",
    "    youTubeNonTrendingData['dislikeCount']=youTubeNonTrendingData[['dislikeCount']].apply(replaceNullByZero,axis=1)\n",
    "    youTubeNonTrendingData['likeCount']=youTubeNonTrendingData[['likeCount']].apply(replaceNullByZero,axis=1)\n",
    "    youTubeNonTrendingData['viewCount']=youTubeNonTrendingData[['viewCount']].apply(replaceNullByZero,axis=1)\n",
    "    #Add trending column with 0 for Non trending Video\n",
    "    youTubeNonTrendingData['trending']=0\n",
    "    \n",
    "    #Convert the Channel ID to Channel Title using the 'channels_dict' Dictionary in Non trending data\n",
    "    with open('channels_dict','rb') as f:\n",
    "        channelDictionary = pickle.load(f)\n",
    "    youTubeNonTrendingData['channel_title']=youTubeNonTrendingData[['channelId']].apply(convertChannelIdToChannelTitle,args=(channelDictionary,),axis=1)\n",
    "    \n",
    "    \n",
    "    #Combine Trending and Non Trending data\n",
    "    #Drop unused features from Trending data and rename the features to match the Columns of Non Trending data\n",
    "    youTubeTrendingDataTemp=youTubeTrendingData.drop(['comments_disabled','ratings_disabled','video_error_or_removed'],axis=1)\n",
    "    youTubeTrendingDataTemp.rename(columns={'trending_date':'obtained_date'}, inplace=True)\n",
    "    #Drop unused features from Non Trending data and rename the features to match the Columns of Trending data\n",
    "    youTubeNonTrendingDataTemp=youTubeNonTrendingData.drop(['duration','dimension','channelId','projection','license','embeddable','licencedContent','privacyStatus','caption','definition','defaultAudioLanguage'],axis=1)\n",
    "    youTubeNonTrendingDataTemp.rename(columns={'V_id':'video_id','categoryId':'category_id','publishedAt':'publish_time','viewCount':'views','likeCount':'likes','dislikeCount':'dislikes','commentCount':'comment_count','thumbnail':'thumbnail_link'}, inplace=True)\n",
    "    #Concatinate trending and non trending data\n",
    "    youTubeData=pd.concat([youTubeTrendingDataTemp,youTubeNonTrendingDataTemp],ignore_index=True)\n",
    "    #Convert the category IDs to category names using the JSON dictionary 'category_id'\n",
    "    categoryDict=categoryIdToCategory()\n",
    "    youTubeData['category_id']=youTubeData[['category_id']].apply(convertCategoryIdToCategory,args=(categoryDict,),axis=1)\n",
    "    return youTubeData,youTubeTrendingDataTemp,youTubeNonTrendingDataTemp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f726c086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequencyOfChannelTitle(columns,channelTitleCount):             #Replaces the Channel Title with its freqeuncy of occurence\n",
    "    channelTitle=columns[0]\n",
    "    if(type(channelTitle)==str):\n",
    "        try:\n",
    "            channelTitleCount=channelTitleCount[1][channelTitle]\n",
    "            return channelTitleCount\n",
    "        except Exception as e:\n",
    "            return 0\n",
    "    else:\n",
    "        return channelTitle\n",
    "\n",
    "\n",
    "def frequencyOfCategory(columns,categoryCount):                 #(Unused method) Replaces the Category ID with its freqeuncy of occurence\n",
    "    category=columns[0]\n",
    "    try:\n",
    "        categoryIdCount=categoryCount[1][category]\n",
    "    except Exception as e:\n",
    "        return 0\n",
    "    return categoryIdCount\n",
    "\n",
    "\n",
    "def prepareTagRanking(youTubeTrendingData):               #Splits the Title and tags from trending data into words,removes nonascii characters, removes stop words and calculates the number occurences these words for ranking  \n",
    "    tags=[]\n",
    "    for tag in youTubeTrendingData['tags']:\n",
    "        if(type(tag) == str):\n",
    "            temp=tag.split('|')\n",
    "            for t in temp:\n",
    "                temp1=t.split()\n",
    "                for t1 in temp1:\n",
    "                    t1=re.sub('[^A-Za-z0-9]+', '', t1).lstrip()\n",
    "                    if (t1):\n",
    "                        tags.append(t1.lower())\n",
    "    \n",
    "    for title in youTubeTrendingData['title']:\n",
    "        if(type(title)==str):\n",
    "            temp=title.split()\n",
    "            for t in temp:\n",
    "                t=re.sub('[^A-Za-z0-9]+', '', t).lstrip()\n",
    "                if(t):\n",
    "                    tags.append(t.lower())\n",
    "    \n",
    "\n",
    "    filtered_tags = [w for w in tags if not w in stop_words]\n",
    "    if(len(filtered_tags)):\n",
    "        tags=pd.DataFrame(data=filtered_tags)\n",
    "        tags.columns=['tags']\n",
    "        tagCount=tags['tags'].value_counts()\n",
    "        return tagCount\n",
    "    return []\n",
    "\n",
    "    \n",
    "def processTag(columns,tagRanking):         #Splits the given tags into words, removes nonascii characters, stop words and calculates the average rank of given tag\n",
    "    tag=columns[0]\n",
    "    trending=columns[1]\n",
    "    tagAfterSplit=[]\n",
    "    if(type(tag)==str):\n",
    "        if(trending==1):\n",
    "            tagFirstSplit=tag.split('|')\n",
    "        else:\n",
    "            tagFirstSplit=tag.split(',')\n",
    "        for t in tagFirstSplit:\n",
    "            tagSecondSplit=t.split()\n",
    "            for t in tagSecondSplit:\n",
    "                t=re.sub('[^^A-Za-z0-9]+','',t).lstrip()\n",
    "                if(t):\n",
    "                    \n",
    "                    tagAfterSplit.append(t.lower())\n",
    "                    \n",
    "        filteredTag=[w for w in tagAfterSplit if not w in stop_words]\n",
    "        filteredUniqueTag=set(filteredTag)\n",
    "        sum=0\n",
    "        for f in filteredUniqueTag:\n",
    "            try:\n",
    "                sum+=int(tagRanking[f])\n",
    "            except Exception as e:\n",
    "                sum+=1\n",
    "        if(len(filteredUniqueTag)>0):\n",
    "            average=(sum/len(filteredUniqueTag))\n",
    "            return average\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        return tag\n",
    "    \n",
    "    \n",
    "def processTitle(columns,wordRanking):          #Splits the given title into words, removes nonascii characters, stop words and calculates the average rank of given title\n",
    "    title=columns[0]\n",
    "    titleAfterSplit=[]\n",
    "    if(type(title)==str):\n",
    "        temp=title.split()\n",
    "        for t in temp:\n",
    "            t=re.sub('[^^A-Za-z0-9]+','',t).lstrip()\n",
    "            if(t):\n",
    "                titleAfterSplit.append(t.lower())\n",
    "        filteredTitle=[w for w in titleAfterSplit if not w in stop_words]\n",
    "        filteredUniqueTitle=set(filteredTitle)\n",
    "        sum=0\n",
    "        for f in filteredUniqueTitle:\n",
    "            try:\n",
    "                sum+=int(wordRanking[f])\n",
    "            except Exception as e:\n",
    "                sum+=1\n",
    "        if(len(filteredUniqueTitle)>0):\n",
    "            average=(sum/len(filteredUniqueTitle))\n",
    "            return average\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        return title\n",
    "\n",
    "\n",
    "def processTheData(youTubeData,youTubeTrendingData):        #processes the data and makes it ready for feature selection\n",
    "    #Calculates the frequency of the channel title in trending videos and replaces the channel title with its frequency\n",
    "    channelTitleCount=youTubeData.groupby('trending')['channel_title'].value_counts() \n",
    "    youTubeData['channel_title']=youTubeData[['channel_title']].apply(frequencyOfChannelTitle, axis=1, args=(channelTitleCount,))\n",
    "    #calculates the tag and video title ranking(i.e the frequnecy of ocuurence of every word) and replaces the video title and tags with its value\n",
    "    tagRanking=prepareTagRanking(youTubeTrendingData)\n",
    "    youTubeData['tags']=youTubeData[['tags','trending']].apply(processTag,axis=1,args=(tagRanking,))\n",
    "    youTubeData['title']=youTubeData[['title']].apply(processTitle,axis=1,args=(tagRanking,))\n",
    "    #Calculates the rate of views, likes and dislikes per day. \n",
    "    youTubeData['rateOfViews']=youTubeData[['views','age']].apply(calculateRate,axis=1)\n",
    "    youTubeData['rateOfLikes']=youTubeData[['likes','age']].apply(calculateRate,axis=1)\n",
    "    #Creates a dummy list for the categorical data Categort IDs and adds these columns to the Data Frame\n",
    "    categoryDummyList = pd.get_dummies(youTubeData['category_id'], prefix='category')\n",
    "    youTubeData=youTubeData.join(categoryDummyList)\n",
    "    return youTubeData\n",
    "\n",
    "def createROCCurve(y_test,y_pred,heading):      #plots ROC Curve\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    y_pred = label_binarize(y_pred,classes=[0,1])\n",
    "    y_test = label_binarize(y_test,classes=[0,1])\n",
    "    n_classes = y_test.shape[1]\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr[0], tpr[0], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[0])\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(heading)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb7ed2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the Data\n",
    "youTubeTrendingData=pd.read_csv(\"C:/Users/VSmart/Projects/TrendingVideos.csv\", encoding = \"UTF-8\",index_col='video_id')\n",
    "youTubeNonTrendingData=pd.read_csv(\"C:/Users/VSmart/Projects/NonTrendingVideos.csv\", encoding = \"UTF-8\",index_col='V_id')\n",
    "youTubeTrendingData=resample(youTubeTrendingData,replace=False,n_samples=len(youTubeNonTrendingData))   #Resampling of Data for balancing Class Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3033675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#youTubeNonTrendingData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54ca487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#youTubeTrendingData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fef667fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-processing the Data\n",
    "youTubeData,youTubeTrendingData,youTubeNonTrendingData=preProcessTheData(youTubeTrendingData,youTubeNonTrendingData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16aa00d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing the combined Trending and Non Trending Data\n",
    "youTubeData=processTheData(youTubeData,youTubeTrendingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8951b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unused features\n",
    "youTubeDataForFeatureSelection=youTubeData.drop(['category_id','description','obtained_date','publish_time','thumbnail_link'],axis=1)\n",
    "#Divide the Data into features and class labels\n",
    "X = youTubeDataForFeatureSelection\n",
    "y = youTubeDataForFeatureSelection[\"trending\"]\n",
    "#Scaling of features\n",
    "X=pre.scale(X)\n",
    "\n",
    "#Selects the most important features from the model to make the model better and reduce the dimensionality\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X, y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = model.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de7a6085",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X, y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = model.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6239b13",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/VSmart/PopVids.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9116/3555241379.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/VSmart/PopVids.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"UTF-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnonpop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/VSmart/NonPopularVids.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"UTF-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/VSmart/PopVids.csv'"
     ]
    }
   ],
   "source": [
    "pop=pd.read_csv(\"C:/Users/VSmart/Projects/PopVids.csv\", encoding = \"UTF-8\")\n",
    "nonpop=pd.read_csv(\"C:/Users/VSmart/Projects/NonPopularVids.csv\", encoding = \"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e9467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonpop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe45cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
